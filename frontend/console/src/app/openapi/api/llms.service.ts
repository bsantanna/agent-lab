/**
 * Agent-Lab
 *
 *
 *
 * NOTE: This class is auto generated by OpenAPI Generator (https://openapi-generator.tech).
 * https://openapi-generator.tech
 * Do not edit the class manually.
 */
/* tslint:disable:no-unused-variable member-ordering */

import {Inject, Injectable, Optional} from '@angular/core';
import {HttpClient, HttpContext, HttpEvent, HttpResponse} from '@angular/common/http';
import {Observable} from 'rxjs';

// @ts-ignore
import {HTTPValidationError} from '../model/hTTPValidationError';
// @ts-ignore
import {LanguageModel} from '../model/languageModel';
// @ts-ignore
import {LanguageModelCreateRequest} from '../model/languageModelCreateRequest';
// @ts-ignore
import {LanguageModelExpanded} from '../model/languageModelExpanded';
// @ts-ignore
import {LanguageModelSettingUpdateRequest} from '../model/languageModelSettingUpdateRequest';
// @ts-ignore
import {LanguageModelUpdateRequest} from '../model/languageModelUpdateRequest';

// @ts-ignore
import {BASE_PATH, COLLECTION_FORMATS} from '../variables';
import {Configuration} from '../configuration';
import {BaseService} from '../api.base.service';


@Injectable({
  providedIn: 'root'
})
export class LlmsService extends BaseService {

  constructor(protected httpClient: HttpClient, @Optional() @Inject(BASE_PATH) basePath: string | string[], @Optional() configuration?: Configuration) {
    super(basePath, configuration);
  }

  /**
   * Add
   * @param languageModelCreateRequest
   * @param observe set whether or not to return the data Observable as the body, response or events. defaults to returning the body.
   * @param reportProgress flag to report request and response progress.
   */
  public addLlmsCreatePost(languageModelCreateRequest: LanguageModelCreateRequest, observe?: 'body', reportProgress?: boolean, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<LanguageModel>;
  public addLlmsCreatePost(languageModelCreateRequest: LanguageModelCreateRequest, observe?: 'response', reportProgress?: boolean, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<HttpResponse<LanguageModel>>;
  public addLlmsCreatePost(languageModelCreateRequest: LanguageModelCreateRequest, observe?: 'events', reportProgress?: boolean, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<HttpEvent<LanguageModel>>;
  public addLlmsCreatePost(languageModelCreateRequest: LanguageModelCreateRequest, observe: any = 'body', reportProgress: boolean = false, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<any> {
    if (languageModelCreateRequest === null || languageModelCreateRequest === undefined) {
      throw new Error('Required parameter languageModelCreateRequest was null or undefined when calling addLlmsCreatePost.');
    }

    let localVarHeaders = this.defaultHeaders;

    const localVarHttpHeaderAcceptSelected: string | undefined = options?.httpHeaderAccept ?? this.configuration.selectHeaderAccept([
      'application/json'
    ]);
    if (localVarHttpHeaderAcceptSelected !== undefined) {
      localVarHeaders = localVarHeaders.set('Accept', localVarHttpHeaderAcceptSelected);
    }

    const localVarHttpContext: HttpContext = options?.context ?? new HttpContext();

    const localVarTransferCache: boolean = options?.transferCache ?? true;


    // to determine the Content-Type header
    const consumes: string[] = [
      'application/json'
    ];
    const httpContentTypeSelected: string | undefined = this.configuration.selectHeaderContentType(consumes);
    if (httpContentTypeSelected !== undefined) {
      localVarHeaders = localVarHeaders.set('Content-Type', httpContentTypeSelected);
    }

    let responseType_: 'text' | 'json' | 'blob' = 'json';
    if (localVarHttpHeaderAcceptSelected) {
      if (localVarHttpHeaderAcceptSelected.startsWith('text')) {
        responseType_ = 'text';
      } else if (this.configuration.isJsonMime(localVarHttpHeaderAcceptSelected)) {
        responseType_ = 'json';
      } else {
        responseType_ = 'blob';
      }
    }

    let localVarPath = `/llms/create`;
    return this.httpClient.request<LanguageModel>('post', `${this.configuration.basePath}${localVarPath}`,
      {
        context: localVarHttpContext,
        body: languageModelCreateRequest,
        responseType: <any>responseType_,
        withCredentials: this.configuration.withCredentials,
        headers: localVarHeaders,
        observe: observe,
        transferCache: localVarTransferCache,
        reportProgress: reportProgress
      }
    );
  }

  /**
   * Get By Id
   * @param languageModelId
   * @param observe set whether or not to return the data Observable as the body, response or events. defaults to returning the body.
   * @param reportProgress flag to report request and response progress.
   */
  public getByIdLlmsLanguageModelIdGet(languageModelId: string, observe?: 'body', reportProgress?: boolean, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<LanguageModelExpanded>;
  public getByIdLlmsLanguageModelIdGet(languageModelId: string, observe?: 'response', reportProgress?: boolean, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<HttpResponse<LanguageModelExpanded>>;
  public getByIdLlmsLanguageModelIdGet(languageModelId: string, observe?: 'events', reportProgress?: boolean, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<HttpEvent<LanguageModelExpanded>>;
  public getByIdLlmsLanguageModelIdGet(languageModelId: string, observe: any = 'body', reportProgress: boolean = false, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<any> {
    if (languageModelId === null || languageModelId === undefined) {
      throw new Error('Required parameter languageModelId was null or undefined when calling getByIdLlmsLanguageModelIdGet.');
    }

    let localVarHeaders = this.defaultHeaders;

    const localVarHttpHeaderAcceptSelected: string | undefined = options?.httpHeaderAccept ?? this.configuration.selectHeaderAccept([
      'application/json'
    ]);
    if (localVarHttpHeaderAcceptSelected !== undefined) {
      localVarHeaders = localVarHeaders.set('Accept', localVarHttpHeaderAcceptSelected);
    }

    const localVarHttpContext: HttpContext = options?.context ?? new HttpContext();

    const localVarTransferCache: boolean = options?.transferCache ?? true;


    let responseType_: 'text' | 'json' | 'blob' = 'json';
    if (localVarHttpHeaderAcceptSelected) {
      if (localVarHttpHeaderAcceptSelected.startsWith('text')) {
        responseType_ = 'text';
      } else if (this.configuration.isJsonMime(localVarHttpHeaderAcceptSelected)) {
        responseType_ = 'json';
      } else {
        responseType_ = 'blob';
      }
    }

    let localVarPath = `/llms/${this.configuration.encodeParam({
      name: "languageModelId",
      value: languageModelId,
      in: "path",
      style: "simple",
      explode: false,
      dataType: "string",
      dataFormat: undefined
    })}`;
    return this.httpClient.request<LanguageModelExpanded>('get', `${this.configuration.basePath}${localVarPath}`,
      {
        context: localVarHttpContext,
        responseType: <any>responseType_,
        withCredentials: this.configuration.withCredentials,
        headers: localVarHeaders,
        observe: observe,
        transferCache: localVarTransferCache,
        reportProgress: reportProgress
      }
    );
  }

  /**
   * Get List
   * @param observe set whether or not to return the data Observable as the body, response or events. defaults to returning the body.
   * @param reportProgress flag to report request and response progress.
   */
  public getListLlmsListGet(observe?: 'body', reportProgress?: boolean, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<Array<LanguageModel>>;
  public getListLlmsListGet(observe?: 'response', reportProgress?: boolean, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<HttpResponse<Array<LanguageModel>>>;
  public getListLlmsListGet(observe?: 'events', reportProgress?: boolean, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<HttpEvent<Array<LanguageModel>>>;
  public getListLlmsListGet(observe: any = 'body', reportProgress: boolean = false, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<any> {

    let localVarHeaders = this.defaultHeaders;

    const localVarHttpHeaderAcceptSelected: string | undefined = options?.httpHeaderAccept ?? this.configuration.selectHeaderAccept([
      'application/json'
    ]);
    if (localVarHttpHeaderAcceptSelected !== undefined) {
      localVarHeaders = localVarHeaders.set('Accept', localVarHttpHeaderAcceptSelected);
    }

    const localVarHttpContext: HttpContext = options?.context ?? new HttpContext();

    const localVarTransferCache: boolean = options?.transferCache ?? true;


    let responseType_: 'text' | 'json' | 'blob' = 'json';
    if (localVarHttpHeaderAcceptSelected) {
      if (localVarHttpHeaderAcceptSelected.startsWith('text')) {
        responseType_ = 'text';
      } else if (this.configuration.isJsonMime(localVarHttpHeaderAcceptSelected)) {
        responseType_ = 'json';
      } else {
        responseType_ = 'blob';
      }
    }

    let localVarPath = `/llms/list`;
    return this.httpClient.request<Array<LanguageModel>>('get', `${this.configuration.basePath}${localVarPath}`,
      {
        context: localVarHttpContext,
        responseType: <any>responseType_,
        withCredentials: this.configuration.withCredentials,
        headers: localVarHeaders,
        observe: observe,
        transferCache: localVarTransferCache,
        reportProgress: reportProgress
      }
    );
  }

  /**
   * Remove
   * @param languageModelId
   * @param observe set whether or not to return the data Observable as the body, response or events. defaults to returning the body.
   * @param reportProgress flag to report request and response progress.
   */
  public removeLlmsDeleteLanguageModelIdDelete(languageModelId: string, observe?: 'body', reportProgress?: boolean, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<any>;
  public removeLlmsDeleteLanguageModelIdDelete(languageModelId: string, observe?: 'response', reportProgress?: boolean, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<HttpResponse<any>>;
  public removeLlmsDeleteLanguageModelIdDelete(languageModelId: string, observe?: 'events', reportProgress?: boolean, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<HttpEvent<any>>;
  public removeLlmsDeleteLanguageModelIdDelete(languageModelId: string, observe: any = 'body', reportProgress: boolean = false, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<any> {
    if (languageModelId === null || languageModelId === undefined) {
      throw new Error('Required parameter languageModelId was null or undefined when calling removeLlmsDeleteLanguageModelIdDelete.');
    }

    let localVarHeaders = this.defaultHeaders;

    const localVarHttpHeaderAcceptSelected: string | undefined = options?.httpHeaderAccept ?? this.configuration.selectHeaderAccept([
      'application/json'
    ]);
    if (localVarHttpHeaderAcceptSelected !== undefined) {
      localVarHeaders = localVarHeaders.set('Accept', localVarHttpHeaderAcceptSelected);
    }

    const localVarHttpContext: HttpContext = options?.context ?? new HttpContext();

    const localVarTransferCache: boolean = options?.transferCache ?? true;


    let responseType_: 'text' | 'json' | 'blob' = 'json';
    if (localVarHttpHeaderAcceptSelected) {
      if (localVarHttpHeaderAcceptSelected.startsWith('text')) {
        responseType_ = 'text';
      } else if (this.configuration.isJsonMime(localVarHttpHeaderAcceptSelected)) {
        responseType_ = 'json';
      } else {
        responseType_ = 'blob';
      }
    }

    let localVarPath = `/llms/delete/${this.configuration.encodeParam({
      name: "languageModelId",
      value: languageModelId,
      in: "path",
      style: "simple",
      explode: false,
      dataType: "string",
      dataFormat: undefined
    })}`;
    return this.httpClient.request<any>('delete', `${this.configuration.basePath}${localVarPath}`,
      {
        context: localVarHttpContext,
        responseType: <any>responseType_,
        withCredentials: this.configuration.withCredentials,
        headers: localVarHeaders,
        observe: observe,
        transferCache: localVarTransferCache,
        reportProgress: reportProgress
      }
    );
  }

  /**
   * Update
   * @param languageModelUpdateRequest
   * @param observe set whether or not to return the data Observable as the body, response or events. defaults to returning the body.
   * @param reportProgress flag to report request and response progress.
   */
  public updateLlmsUpdatePost(languageModelUpdateRequest: LanguageModelUpdateRequest, observe?: 'body', reportProgress?: boolean, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<LanguageModel>;
  public updateLlmsUpdatePost(languageModelUpdateRequest: LanguageModelUpdateRequest, observe?: 'response', reportProgress?: boolean, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<HttpResponse<LanguageModel>>;
  public updateLlmsUpdatePost(languageModelUpdateRequest: LanguageModelUpdateRequest, observe?: 'events', reportProgress?: boolean, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<HttpEvent<LanguageModel>>;
  public updateLlmsUpdatePost(languageModelUpdateRequest: LanguageModelUpdateRequest, observe: any = 'body', reportProgress: boolean = false, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<any> {
    if (languageModelUpdateRequest === null || languageModelUpdateRequest === undefined) {
      throw new Error('Required parameter languageModelUpdateRequest was null or undefined when calling updateLlmsUpdatePost.');
    }

    let localVarHeaders = this.defaultHeaders;

    const localVarHttpHeaderAcceptSelected: string | undefined = options?.httpHeaderAccept ?? this.configuration.selectHeaderAccept([
      'application/json'
    ]);
    if (localVarHttpHeaderAcceptSelected !== undefined) {
      localVarHeaders = localVarHeaders.set('Accept', localVarHttpHeaderAcceptSelected);
    }

    const localVarHttpContext: HttpContext = options?.context ?? new HttpContext();

    const localVarTransferCache: boolean = options?.transferCache ?? true;


    // to determine the Content-Type header
    const consumes: string[] = [
      'application/json'
    ];
    const httpContentTypeSelected: string | undefined = this.configuration.selectHeaderContentType(consumes);
    if (httpContentTypeSelected !== undefined) {
      localVarHeaders = localVarHeaders.set('Content-Type', httpContentTypeSelected);
    }

    let responseType_: 'text' | 'json' | 'blob' = 'json';
    if (localVarHttpHeaderAcceptSelected) {
      if (localVarHttpHeaderAcceptSelected.startsWith('text')) {
        responseType_ = 'text';
      } else if (this.configuration.isJsonMime(localVarHttpHeaderAcceptSelected)) {
        responseType_ = 'json';
      } else {
        responseType_ = 'blob';
      }
    }

    let localVarPath = `/llms/update`;
    return this.httpClient.request<LanguageModel>('post', `${this.configuration.basePath}${localVarPath}`,
      {
        context: localVarHttpContext,
        body: languageModelUpdateRequest,
        responseType: <any>responseType_,
        withCredentials: this.configuration.withCredentials,
        headers: localVarHeaders,
        observe: observe,
        transferCache: localVarTransferCache,
        reportProgress: reportProgress
      }
    );
  }

  /**
   * Update Setting
   * @param languageModelSettingUpdateRequest
   * @param observe set whether or not to return the data Observable as the body, response or events. defaults to returning the body.
   * @param reportProgress flag to report request and response progress.
   */
  public updateSettingLlmsUpdateSettingPost(languageModelSettingUpdateRequest: LanguageModelSettingUpdateRequest, observe?: 'body', reportProgress?: boolean, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<LanguageModelExpanded>;
  public updateSettingLlmsUpdateSettingPost(languageModelSettingUpdateRequest: LanguageModelSettingUpdateRequest, observe?: 'response', reportProgress?: boolean, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<HttpResponse<LanguageModelExpanded>>;
  public updateSettingLlmsUpdateSettingPost(languageModelSettingUpdateRequest: LanguageModelSettingUpdateRequest, observe?: 'events', reportProgress?: boolean, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<HttpEvent<LanguageModelExpanded>>;
  public updateSettingLlmsUpdateSettingPost(languageModelSettingUpdateRequest: LanguageModelSettingUpdateRequest, observe: any = 'body', reportProgress: boolean = false, options?: {
    httpHeaderAccept?: 'application/json',
    context?: HttpContext,
    transferCache?: boolean
  }): Observable<any> {
    if (languageModelSettingUpdateRequest === null || languageModelSettingUpdateRequest === undefined) {
      throw new Error('Required parameter languageModelSettingUpdateRequest was null or undefined when calling updateSettingLlmsUpdateSettingPost.');
    }

    let localVarHeaders = this.defaultHeaders;

    const localVarHttpHeaderAcceptSelected: string | undefined = options?.httpHeaderAccept ?? this.configuration.selectHeaderAccept([
      'application/json'
    ]);
    if (localVarHttpHeaderAcceptSelected !== undefined) {
      localVarHeaders = localVarHeaders.set('Accept', localVarHttpHeaderAcceptSelected);
    }

    const localVarHttpContext: HttpContext = options?.context ?? new HttpContext();

    const localVarTransferCache: boolean = options?.transferCache ?? true;


    // to determine the Content-Type header
    const consumes: string[] = [
      'application/json'
    ];
    const httpContentTypeSelected: string | undefined = this.configuration.selectHeaderContentType(consumes);
    if (httpContentTypeSelected !== undefined) {
      localVarHeaders = localVarHeaders.set('Content-Type', httpContentTypeSelected);
    }

    let responseType_: 'text' | 'json' | 'blob' = 'json';
    if (localVarHttpHeaderAcceptSelected) {
      if (localVarHttpHeaderAcceptSelected.startsWith('text')) {
        responseType_ = 'text';
      } else if (this.configuration.isJsonMime(localVarHttpHeaderAcceptSelected)) {
        responseType_ = 'json';
      } else {
        responseType_ = 'blob';
      }
    }

    let localVarPath = `/llms/update_setting`;
    return this.httpClient.request<LanguageModelExpanded>('post', `${this.configuration.basePath}${localVarPath}`,
      {
        context: localVarHttpContext,
        body: languageModelSettingUpdateRequest,
        responseType: <any>responseType_,
        withCredentials: this.configuration.withCredentials,
        headers: localVarHeaders,
        observe: observe,
        transferCache: localVarTransferCache,
        reportProgress: reportProgress
      }
    );
  }

}
